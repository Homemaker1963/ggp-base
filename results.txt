We were unable to gather any meaningful stats here for a couple of reasons.

First: we're not completely sure that we've implemented the goal distance
heuristic correctly for all possible kinds of statements it needs to expand
(e.g. distincts, nots, trues with variables, etc).  For games with really basic
rules like tic-tac-toe it works, but our player is so fast at searching these
simple games that the heuristic effectively never gets used.

For more complicated games (e.g. Connect Four) we're not sure if the resulting
heuristic values are *real* or are just the result of multiplying "don't know"
a bunch of times, and we don't have enough time to spend the hours it would
require to debug it.

For simple single player games the heuristics are basically useless.  Our player
doesn't do any pruning in single player (except after finding a 100), so all
they do is slow things down.  The only time they *might* help is if the player
can't solve the entire tree in the beginning, and the heuristic might somehow
make it guess the right path.  But we couldn't think of any single player games
where this might be the case (and where one of the heuristics is obviously
useful) to test with.

We've also had a tough time finding two-player games where one of the mobility
heuristics (which are the only ones we're even remotely confident that we've
implemented correctly) should help us consistently.

Finally, actually running hundreds of tests (each of which takes a minute or
more) to try to get some statistical confidence would take more time than we
have left to hand this in.  It just took too long to get the alpha/beta working
at all to start, then trying to add in heuristics and do a lot of testing all in
one day wasn't possible.
